{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "def combine_drawn_boxes(rectangles, proximity_threshold=30):\n",
    "    \"\"\"\n",
    "    Combine bounding boxes that are close to each other.\n",
    "    :param rectangles: List of drawn bounding boxes [(x, y, w, h), ...]\n",
    "    :param proximity_threshold: Distance threshold to combine boxes\n",
    "    :return: List of combined bounding boxes [(x, y, w, h), ...]\n",
    "    \"\"\"\n",
    "    combined_boxes = []\n",
    "\n",
    "    for box in rectangles:\n",
    "        x, y, w, h = box\n",
    "        merged = False\n",
    "        for i, (cx, cy, cw, ch) in enumerate(combined_boxes):\n",
    "            # Check if boxes are close based on proximity threshold\n",
    "            if (abs(x - cx) < proximity_threshold and abs(y - cy) < proximity_threshold) or \\\n",
    "               (abs((x + w) - (cx + cw)) < proximity_threshold and abs((y + h) - (cy + ch)) < proximity_threshold):\n",
    "                # Merge boxes\n",
    "                nx = min(x, cx)\n",
    "                ny = min(y, cy)\n",
    "                nw = max(x + w, cx + cw) - nx\n",
    "                nh = max(y + h, cy + ch) - ny\n",
    "                combined_boxes[i] = (nx, ny, nw, nh)\n",
    "                merged = True\n",
    "                break\n",
    "        if not merged:\n",
    "            combined_boxes.append((x, y, w, h))\n",
    "\n",
    "    return combined_boxes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import os\n",
    "\n",
    "CROP_X = 357\n",
    "CROP_Y = 256\n",
    "CROP_WIDTH = 574  \n",
    "CROP_HEIGHT = 1002 \n",
    "\n",
    "# Paths to images\n",
    "background_image_path = './datasets/video-frames/background.png'  # Frame with just the background\n",
    "background = cv2.imread(background_image_path)\n",
    "\n",
    "def cleanup(frame, suppress_others=True, enlarge=False, kernel_size=7, iterations=3):\n",
    "    # Ensure images are the same size\n",
    "    if background.shape != frame.shape:\n",
    "        print(\"Error: Background and bee frame must have the same dimensions.\")\n",
    "        return\n",
    "    else:\n",
    "        # Subtract the background directly in color\n",
    "        diff = cv2.absdiff(frame, background)\n",
    "\n",
    "        # Convert diff to HSV\n",
    "        hsv_diff = cv2.cvtColor(diff, cv2.COLOR_BGR2HSV)\n",
    "\n",
    "        # Define HSV ranges for red, yellow, and orange\n",
    "        lower_red1 = np.array([0, 100, 100])     # Lower range for red (hue 0-10)\n",
    "        upper_red1 = np.array([10, 255, 255])\n",
    "        lower_red2 = np.array([160, 100, 100])   # Upper range for red (hue 160-180)\n",
    "        upper_red2 = np.array([180, 255, 255])\n",
    "        lower_yellow = np.array([20, 100, 100])  # Range for yellow\n",
    "        upper_yellow = np.array([30, 255, 255])\n",
    "        lower_orange = np.array([10, 100, 100])  # Range for orange\n",
    "        upper_orange = np.array([20, 255, 255])\n",
    "\n",
    "        # Create masks for each color\n",
    "        red_mask1 = cv2.inRange(hsv_diff, lower_red1, upper_red1)\n",
    "        red_mask2 = cv2.inRange(hsv_diff, lower_red2, upper_red2)\n",
    "        yellow_mask = cv2.inRange(hsv_diff, lower_yellow, upper_yellow)\n",
    "        orange_mask = cv2.inRange(hsv_diff, lower_orange, upper_orange)\n",
    "\n",
    "        # Combine all masks\n",
    "        combined_mask = cv2.bitwise_or(red_mask1, red_mask2)\n",
    "        combined_mask = cv2.bitwise_or(combined_mask, yellow_mask)\n",
    "        combined_mask = cv2.bitwise_or(combined_mask, orange_mask)\n",
    "\n",
    "        if enlarge:\n",
    "            # Dilate the mask to enlarge the regions\n",
    "            kernel = cv2.getStructuringElement(cv2.MORPH_ELLIPSE, (kernel_size, kernel_size))\n",
    "            combined_mask = cv2.dilate(combined_mask, kernel, iterations=iterations)\n",
    "\n",
    "        # Enhance the selected regions\n",
    "        enhanced = cv2.addWeighted(diff, 1.0, diff, 0.1, 0)\n",
    "        enhanced_regions = cv2.bitwise_and(enhanced, enhanced, mask=combined_mask)\n",
    "\n",
    "        if suppress_others:\n",
    "            # Suppress non-target colors\n",
    "            inverse_mask = cv2.bitwise_not(combined_mask)  # Non-target areas\n",
    "            suppressed = cv2.addWeighted(diff, 0.7, diff, 0.0, 0)  # Reduce intensity of non-target areas\n",
    "            suppressed_regions = cv2.bitwise_and(suppressed, suppressed, mask=inverse_mask)\n",
    "\n",
    "            # Combine enhanced and suppressed regions\n",
    "            final_result = cv2.addWeighted(enhanced_regions, 1, suppressed_regions, 1.0, 0)\n",
    "        else:\n",
    "            final_result = enhanced_regions\n",
    "\n",
    "        return final_result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Finished processing cropped_muted_1.mp4. Saved to ./datasets/pre-processed-mobile-videos/w_boxed_cropped_muted_1.mp4\n"
     ]
    }
   ],
   "source": [
    "       \n",
    "# Define video paths\n",
    "video_dir = './datasets/mobile-videos'\n",
    "videos = [\"cropped_muted_1.mp4\"]\n",
    "from matplotlib import pyplot as plt\n",
    "\n",
    "\n",
    "# Define output directory\n",
    "output_dir = './datasets/pre-processed-mobile-videos'\n",
    "os.makedirs(output_dir, exist_ok=True)\n",
    "\n",
    "\n",
    "# Process each video\n",
    "for video_name in videos:\n",
    "    video_path = os.path.join(video_dir, video_name)\n",
    "    cap = cv2.VideoCapture(video_path)\n",
    "    \n",
    "    if not cap.isOpened():\n",
    "        print(f\"Error: Cannot open {video_name}\")\n",
    "        continue\n",
    "\n",
    "\n",
    "    # Output video writer\n",
    "    output_video_path = os.path.join(output_dir, f\"boxed_{video_name}\")\n",
    "    out = cv2.VideoWriter(output_video_path, cv2.VideoWriter_fourcc(*'mp4v'), 29, # 29 can be given as an return value of the pirnt_details method\n",
    "                          (CROP_WIDTH, CROP_HEIGHT))\n",
    "\n",
    "    frame_idx = 0\n",
    "    while cap.isOpened():\n",
    "        ret, frame = cap.read()\n",
    "        if not ret:\n",
    "            break\n",
    "        \n",
    "        #-----BEE DETECTION-----\n",
    "        processed_frame = cleanup(frame, enlarge=True)\n",
    "        processed_frame[np.all(processed_frame < 20, axis=-1)] = 0\n",
    "        non_black_mask = cv2.inRange(processed_frame, (1, 1, 1), (255, 255, 255))  # Anything above (0, 0, 0)\n",
    "\n",
    "        # Find contours of non-black regions\n",
    "        contours, _ = cv2.findContours(non_black_mask, cv2.RETR_EXTERNAL, cv2.CHAIN_APPROX_SIMPLE)\n",
    "        rectangles = []\n",
    "\n",
    "        # Draw bounding boxes around detected non-black regions\n",
    "        for contour in contours:\n",
    "            x, y, w, h = cv2.boundingRect(contour)\n",
    "            if w > 15 and h > 15:  # Exclude very small detections\n",
    "                # cv2.rectangle(frame, (x, y), (x + w, y + h), (0, 255, 0), 2)  # Green bounding box #this is not needed    \n",
    "                rectangles.append((x, y, w, h))  # Collect rectangle coordinates\n",
    "        \n",
    "        # Combine close rectangles\n",
    "        combined_boxes = combine_drawn_boxes(rectangles, proximity_threshold=30)\n",
    "        number_of_bees = len(combined_boxes)\n",
    "\n",
    "        # Draw combined bounding boxes\n",
    "        for x, y, w, h in combined_boxes:\n",
    "            cv2.rectangle(frame, (x, y), (x + w, y + h), (255, 0, 0), 2)  # Draw final boxes in Blue\n",
    "        \n",
    "\n",
    " \n",
    "        #-----POLLEN DETECTION-----\n",
    "        only_pollen_frame = cleanup(frame, enlarge=True, suppress_others=False)\n",
    "        # Find contours of non-black regions\n",
    "        non_black_mask = cv2.inRange(only_pollen_frame, (5, 5, 5), (255, 255, 255))  # Anything above (5, 5, 5) -- try out more thresholds\n",
    "        \n",
    "\n",
    "        contours, _ = cv2.findContours(non_black_mask, cv2.RETR_EXTERNAL, cv2.CHAIN_APPROX_SIMPLE)\n",
    "            # Store all drawn boxes\n",
    "        rectangles = []\n",
    "\n",
    "        # Draw bounding boxes around detected non-black regions\n",
    "        for contour in contours:\n",
    "            x, y, w, h = cv2.boundingRect(contour)\n",
    "            if w > 20 and h > 20:  # Exclude very small detections\n",
    "                # cv2.rectangle(frame, (x, y), (x + w, y + h), (40, 155, 0), 2)  # Green bounding box    \n",
    "                rectangles.append((x, y, w, h))  # Collect rectangle coordinates\n",
    "        \n",
    "        # Combine close rectangles\n",
    "        combined_boxes = combine_drawn_boxes(rectangles, proximity_threshold=50)\n",
    "        number_of_pollen = len(combined_boxes)\n",
    "\n",
    "        # Draw combined bounding boxes\n",
    "        for x, y, w, h in combined_boxes:\n",
    "            cv2.rectangle(frame, (x, y), (x + w, y + h), (0, 0, 255), 2)  # Draw final boxes in Red\n",
    "        \n",
    "        \n",
    "        # Add number_of_bees and number_of_pollen text to the frame in two lines\n",
    "        text1 = f\"Number of Bees: {number_of_bees}\"\n",
    "        text2 = f\"Number of Bees with Pollen: {number_of_pollen}\"\n",
    "\n",
    "        font = cv2.FONT_HERSHEY_SIMPLEX\n",
    "        font_scale = 1\n",
    "        color_bee = (255, 0, 0 )  # Blue color\n",
    "        color_pollen = (0, 0, 255)  # Red color\n",
    "        thickness = 2\n",
    "\n",
    "        # Calculate text size for alignment\n",
    "        text1_size = cv2.getTextSize(text1, font, font_scale, thickness)[0]\n",
    "        text2_size = cv2.getTextSize(text2, font, font_scale, thickness)[0]\n",
    "\n",
    "        # Define text positions\n",
    "        text_x = 10\n",
    "        text1_y = text1_size[1] + 10  # Add padding for the first line\n",
    "        text2_y = text1_y + text2_size[1] + 10  # Add padding for the second line\n",
    "\n",
    "        # Add text to the frame\n",
    "        cv2.putText(frame, text1, (text_x, text1_y), font, font_scale, color_bee, thickness)\n",
    "        cv2.putText(frame, text2, (text_x, text2_y), font, font_scale, color_pollen, thickness)\n",
    "     \n",
    "        out.write(frame)\n",
    "\n",
    "        # # Display every 1000th frame\n",
    "        # if frame_idx % 200 == 0:\n",
    "        #     display_frame(processed_frame, title=f\"Processed Frame {frame_idx}\")\n",
    "\n",
    "        frame_idx += 1\n",
    "\n",
    "    cap.release()\n",
    "    out.release()\n",
    "    print(f\"Finished processing {video_name}. Saved to {output_video_path}\")\n",
    "\n",
    "    \n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "beehive",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.21"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
